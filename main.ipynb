{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce81d826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"animal\": {\n",
      "    \"name\": \"cat\",\n",
      "    \"sound\": \"meow\"\n",
      "  },\n",
      "  \"setup\": \"Why was the cat sitting on the computer?\",\n",
      "  \"punchline\": \"Because it wanted to keep an eye on the mouse!\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# Pydantic\n",
    "class Animal(BaseModel):\n",
    "    \"\"\"Animal to tell user.\"\"\"\n",
    "\n",
    "    name: str = Field(description=\"The name of the animal\")\n",
    "    sound: str = Field(description=\"The sound the animal makes\")\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    \"\"\"Joke to tell user.\"\"\"\n",
    "\n",
    "    animal: Animal = Field(description=\"The animal in the joke\")\n",
    "    setup: str = Field(description=\"The setup of the joke\")\n",
    "    punchline: str = Field(description=\"The punchline to the joke\")\n",
    "\n",
    "structured_llm = LLM.with_structured_output(Joke)\n",
    "\n",
    "result = structured_llm.invoke(\"Tell me a joke about cats\")\n",
    "result_json = json.dumps(result.model_dump(), indent=2)\n",
    "print(result_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f73d416",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n",
      "CropBox missing from /Page, defaulting to MediaBox\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"metadata\": {\n",
      "    \"document_title\": \"Proposed Teamfood Homepage Changes\",\n",
      "    \"document_date\": \"2024-12-25\",\n",
      "    \"document_status\": \"DRAFT/REVIEWED\",\n",
      "    \"document_author\": \"Ian Chiu\"\n",
      "  },\n",
      "  \"person\": {\n",
      "    \"name\": \"Ian Chiu\",\n",
      "    \"role\": \"\",\n",
      "    \"email\": \"\"\n",
      "  },\n",
      "  \"problem\": {\n",
      "    \"vision_opportunity\": \"Address user confusion on first landing and improve onboarding for new users.\",\n",
      "    \"target_use_case\": \"New users landing on the homepage who are unfamiliar with the product.\"\n",
      "  },\n",
      "  \"solution\": {\n",
      "    \"goals\": \"Reduce user confusion and help people get started on the product faster. Propose cheap short-term fixes that can be implemented quickly.\",\n",
      "    \"conceptual_model\": \"Simplified homepage with clear messaging, guidance, and a single call-to-action for creating the first workspace or table.\",\n",
      "    \"requirements\": [\n",
      "      \"[P0] When no workspaces or tables are present, display information about product use and provide links to help materials.\",\n",
      "      \"[P0] When no workspaces or tables are present, give a clear, prominent call-to-action for getting started.\",\n",
      "      \"[P1] Ensure help materials are accessible from any screen, e.g., via a help icon.\",\n",
      "      \"[P1] Enable users to create a new workspace by default; hide or modify the +New button for creating new tables.\",\n",
      "      \"[P2] Clarify the differences between homepage menu items such as 'All workspaces', 'All tables', and 'Recent'.\",\n",
      "      \"Hide the 'Recent tables' section from the homepage, possibly reintroduce later as a 'popular tables' feature.\"\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from markitdown import MarkItDown\n",
    "\n",
    "GITHUB_TOKEN = os.environ.get(\"GITHUB_TOKEN\") or st.secrets.get(\"GITHUB_TOKEN\")\n",
    "OPEN_AI_API_KEY = os.environ.get(\"OPEN_AI_API_KEY\") or st.secrets.get(\"OPEN_AI_API\")\n",
    "\n",
    "LLM = ChatOpenAI(\n",
    "    model_name=\"gpt-4.1-nano\",\n",
    "    temperature=1,\n",
    "    openai_api_key=OPEN_AI_API_KEY,\n",
    ")\n",
    "\n",
    "# LLM = AzureChatOpenAI(\n",
    "#     azure_endpoint=\"https://models.inference.ai.azure.com\",\n",
    "#     azure_deployment=\"gpt-4.1-nano\",\n",
    "#     openai_api_version=\"2025-03-01-preview\", \n",
    "#     model_name=\"gpt-4.1-nano\",\n",
    "#     temperature=1,\n",
    "#     api_key=GITHUB_TOKEN,\n",
    "# )\n",
    "\n",
    "# Pydantic\n",
    "class Metadata(BaseModel):\n",
    "    \"\"\"Metadata of the document.\"\"\"\n",
    "    document_title: str = Field(description=\"The name of the document\", default=\"\")\n",
    "    document_date: str = Field(description=\"The date of the document\", default=\"\")\n",
    "    document_status: str = Field(description=\"The status of the document\", default=\"\")\n",
    "    document_author: str = Field(description=\"The author of the document\", default=\"\")\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Person in the document beside the author.\"\"\"\n",
    "    name: str = Field(description=\"The name of the person\")\n",
    "    role: str = Field(description=\"The role of the person\")\n",
    "    email: str = Field(description=\"The email of the person\")\n",
    "\n",
    "class Problem(BaseModel):\n",
    "    \"\"\"Overview of the meeting minutes\"\"\"\n",
    "    vision_opportunity: str = Field(description=\"The Vision & Opportunity of the document\")\n",
    "    target_use_case: str = Field(description=\"The Target Use Case of the document\")\n",
    "\n",
    "class Solution(BaseModel):\n",
    "    \"\"\"Solution to the problem\"\"\"\n",
    "    goals: str = Field(description=\"The goals of the solution\")\n",
    "    conceptual_model: str = Field(description=\"The conceptual model of the solution\")\n",
    "    requirements: List[str] = Field(description=\"The requirements of the solution\")\n",
    "\n",
    "class Summary(BaseModel):\n",
    "    metadata: Metadata = Field(description=\"The metadata of the document\")\n",
    "    person: Person = Field(description=\"The person in the document\")\n",
    "    problem: Problem = Field(description=\"The problem in the document\")\n",
    "    solution: Solution = Field(description=\"The solution in the document\")\n",
    "\n",
    "summary_parser = PydanticOutputParser(pydantic_object=Summary)\n",
    "\n",
    "def extract_prd(prd):\n",
    "    prd_template = \"\"\"\"\n",
    "    You are an expert in analyzing Product Requirements Documents (PRDs).\n",
    "    Your task is to extract software requirements from the provided PRD text.\n",
    "    \n",
    "    PRD text: {prd}\n",
    "    \n",
    "    For each PRD text, provide the following information:\n",
    "    {format_instructions}\n",
    "    \n",
    "    If a section doesn't contain any requirements, output nothing for that section.\n",
    "    \"\"\"\n",
    "\n",
    "    prd_prompt_template = PromptTemplate(\n",
    "        input_variables=[\"prd\"],\n",
    "        template=prd_template,\n",
    "        partial_variables={\"format_instructions\": summary_parser.get_format_instructions()},\n",
    "    )\n",
    "\n",
    "    chain = prd_prompt_template | LLM | summary_parser\n",
    "    output = chain.invoke(input={\"prd\": prd})\n",
    "    return output\n",
    "\n",
    "def convert_to_md(input_file):\n",
    "    md = MarkItDown()\n",
    "    result = md.convert(input_file)\n",
    "    return result.text_content\n",
    "\n",
    "text = convert_to_md(\"Test.pdf\")\n",
    "summary = extract_prd(text)\n",
    "print(summary.model_dump_json(indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
